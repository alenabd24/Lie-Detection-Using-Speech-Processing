{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91MsGMTna_P9"
   },
   "source": [
    "# ECS7020P mini-project submission\n",
    "\n",
    "\n",
    "## What is the problem?\n",
    "\n",
    "This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **30 seconds** of duration and predicts whether the story being narrated is **true or not**. \n",
    "\n",
    "\n",
    "## Which dataset will I use?\n",
    "\n",
    "A total of 100 samples consisting of a complete audio recording, a *Language* attribute and a *Story Type* attribute have been made available for you to build your machine learning model. The audio recordings can be downloaded from:\n",
    "\n",
    "https://github.com/MLEndDatasets/Deception/tree/main/MLEndDD_stories_small\n",
    "\n",
    "A CSV file recording the *Language* attribute and *Story Type* of each audio file can be downloaded from:\n",
    "\n",
    "https://github.com/MLEndDatasets/Deception/blob/main/MLEndDD_story_attributes_small.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What will I submit?\n",
    "\n",
    "Your submission will consist of **one single Jupyter notebook** that should include:\n",
    "\n",
    "*   **Text cells**, describing in your own words, rigorously and concisely your approach, each implemented step and the results that you obtain,\n",
    "*   **Code cells**, implementing each step,\n",
    "*   **Output cells**, i.e. the output from each code cell,\n",
    "\n",
    "Your notebook **should have the structure** outlined below. Please make sure that you **run all the cells** and that the **output cells are saved** before submission. \n",
    "\n",
    "Please save your notebook as:\n",
    "\n",
    "* ECS7020P_miniproject_2425.ipynb\n",
    "\n",
    "\n",
    "## How will my submission be evaluated?\n",
    "\n",
    "This submission is worth 16 marks. We will value:\n",
    "\n",
    "*   Conciseness in your writing.\n",
    "*   Correctness in your methodology.\n",
    "*   Correctness in your analysis and conclusions.\n",
    "*   Completeness.\n",
    "*   Originality and efforts to try something new.\n",
    "\n",
    "**The final performance of your solutions will not influence your grade**. We will grade your understanding. If you have an good understanding, you will be using the right methodology, selecting the right approaches, assessing correctly the quality of your solutions, sometimes acknowledging that despite your attempts your solutions are not good enough, and critically reflecting on your work to suggest what you could have done differently. \n",
    "\n",
    "Note that **the problem that we are intending to solve is very difficult**. Do not despair if you do not get good results, **difficulty is precisely what makes it interesting** and **worth trying**. \n",
    "\n",
    "## Show the world what you can do \n",
    "\n",
    "Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. **Potential employers are always looking for this kind of evidence**. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------- PLEASE USE THE STRUCTURE BELOW THIS LINE --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Your title goes here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaGn4ICrfqXZ"
   },
   "source": [
    "# 1. Author\n",
    "\n",
    "**Student Name**:  Alen Abdrakhmanov\n",
    "\n",
    "**Student ID**:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o38VQkcdKd6k"
   },
   "source": [
    "# 2. Problem formulation\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "Deception plays a crucial role in various domains such as criminal investigations and fraud prevention. Deception detection traditionally relies on invasive methods like polygraphs or behavioral analysis, which require direct interaction with the subject. This project adopts a **non-invasive approach** by analyzing audio recordings and leveraging machine learning to classify the recorded stories as truthful or deceptive using **acoustic features**, which will be carefully formulated and presented later.\n",
    "\n",
    "---\n",
    "\n",
    "### **Research Question**\n",
    "\n",
    "Can a machine learning model, trained on extracted audio features, accurately distinguish between truthful and deceptive speech in audio recordings, in various natural languages?\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "To design and implement a machine learning-based system that can classify audio recordings into **truthful** or **deceptive** categories using **non-invasive speech & signal processing techniques**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Scope**\n",
    "\n",
    "#### **Data Scope**\n",
    "- **100 speech audio recordings** in multiple languages (e.g., Hindi, English, Bengali).\n",
    "- Labels indicating whether the speech is truthful or deceptive.\n",
    "\n",
    "#### **Feature Scope**\n",
    "- Extracted features such as:\n",
    "  - **Mel-Frequency Cepstral Coefficients (MFCCs)**\n",
    "  - **Pitch**\n",
    "  - **Jitter**\n",
    "  - **Intensity**\n",
    "- Focus on **acoustic and prosodic characteristics** to detect psycho-emotional cues related to deception.\n",
    "\n",
    "#### **Modeling Scope**\n",
    "- Use a machine learning classifier (**Support Vector Machine**) for binary classification.\n",
    "- Explore performance across various feature combinations and preprocessing methods.\n",
    "\n",
    "---\n",
    "\n",
    "### **Constraints**\n",
    "\n",
    "#### **Data Availability**\n",
    "- Limited labeled datasets for truthful and deceptive speech (**only 100 data points**).\n",
    "- Variability in audio quality and speaker diversity.\n",
    "\n",
    "#### **Model Performance**\n",
    "- Achieve a balance between **accuracy** and **generalization** across different speakers and languages.\n",
    "\n",
    "#### **Real-Time Applicability**\n",
    "- Potential need for efficient processing pipelines to classify speech in real-time.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPTSuaB9L2jU"
   },
   "source": [
    "# 3. Methodology\n",
    "\n",
    "To mirror the machine learning pipeline, the report will be split into **training** and **validation** sections:\n",
    "\n",
    "\n",
    "## **Training Task**\n",
    "\n",
    "The training task focuses on building a **binary classification model** to distinguish between truthful and deceptive audio recordings. It involves the following steps:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Data Preparation**\n",
    "1. Load the dataset of audio recordings with associated labels (`truthful_story` or `deceptive_story`).\n",
    "2. Perform an **initial split** of the dataset into:\n",
    "   - **Training set**: 80% of the data.\n",
    "   - **Test set**: 20% of the data (reserved for final evaluation after training and validation are complete).\n",
    "3. Ensure stratified sampling to balance:\n",
    "   - **Languages** (e.g., Hindi, English, Bengali).\n",
    "   - **Story Types** (`truthful_story`, `deceptive_story`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Data Preprocessing**\n",
    "1. **Noise Reduction:**\n",
    "   - Apply Short-Time Fourier Transform (STFT) thresholding to remove background noise.\n",
    "   \n",
    "2. **Segmentation and Windowing:**\n",
    "   - Divide each audio recording into short frames (e.g., 25 ms with 10 ms overlap).\n",
    "   \n",
    "3. **Feature Extraction:**\n",
    "   - Compute relevant features:\n",
    "     - **MFCCs**: Captures spectral properties of the speech.\n",
    "     - **Prosodic Features**: Includes pitch, jitter, shimmer, and intensity.\n",
    "     \n",
    "4. **Normalization:**\n",
    "   - Scale feature values to ensure consistency across all samples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Model Selection**\n",
    "1. Use **Support Vector Machines (SVM)** as the primary classifier for binary classification.\n",
    "2. Choose kernels based on task requirements:\n",
    "   - **Gaussian (RBF) Kernel**: Handles non-linear relationships.\n",
    "   - **Polynomial Kernel**: Captures complex interactions in features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Model Training**\n",
    "1. Train the model on the **training set** (80% of the dataset).\n",
    "2. Use initial default hyperparameters for the SVM (e.g., `C`, kernel parameters) to establish a baseline.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Model Saving**\n",
    "1. Save the trained model after initial training for further use in validation and hyperparameter optimization.\n",
    "2. Prepare for validation to assess performance and fine-tune the model.\n",
    "\n",
    "---\n",
    "\n",
    "# **Validation Task**\n",
    "\n",
    "The validation task ensures the trained model generalises well to unseen data and optimizes its performance. It involves the following steps:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Validation Data Preparation**\n",
    "1. Use a **subset of the training set** (e.g., 10% of the total dataset) as the **validation set**.\n",
    "2. Ensure the validation set is balanced with stratified sampling for `Language` and `Story_type`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Hyperparameter Tuning**\n",
    "1. Optimize the following SVM hyperparameters:\n",
    "   - **Regularization (`C`)**: Controls the trade-off between margin size and classification errors.\n",
    "   - **Kernel-specific parameters** (e.g., `gamma` for RBF kernel or `degree` for polynomial kernel).\n",
    "2. Use **Grid Search** or **Random Search**:\n",
    "   - Evaluate combinations of hyperparameters on the validation set.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Cross-Validation**\n",
    "1. Apply **k-fold cross-validation** (e.g., 5-fold) within the training data to:\n",
    "   - Avoid overfitting or underfitting.\n",
    "   - Assess model consistency across different data splits.\n",
    "2. Evaluate the model using:\n",
    "   - Accuracy.\n",
    "   - F1-Score.\n",
    "   - AUC-ROC.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Evaluation**\n",
    "1. Evaluate model performance based on a group of metrics:\n",
    "   - **Accuracy**: Overall correctness of predictions.\n",
    "   - **F1-Score**: Balances precision and recall, especially useful for imbalanced data.\n",
    "   - **Confusion Matrix**: Examines true/false positives and negatives.\n",
    "   - **AUC-ROC**: Analyzes the model’s ability to distinguish between classes.\n",
    "\n",
    "2. Use validation metrics to guide improvements:\n",
    "   - Adjust features if necessary (e.g., add delta MFCCs).\n",
    "   - Fine-tune hyperparameters for better generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3BwrtEdLDit"
   },
   "source": [
    "# 4 Implemented ML prediction pipelines\n",
    "\n",
    "Describe the ML prediction pipelines that you will explore. Clearly identify their input and output, stages and format of the intermediate data structures moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. After providing an overview, describe in more detail each one of the stages that you have included in their corresponding subsections (i.e. 4.1 Transformation stage, 4.2 Model stage, 4.3 Ensemble stage).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Visualization of the Pipeline**\n",
    "1. **Input:**\n",
    "   - Raw audio files + labels.\n",
    "2. **Preprocessing:**\n",
    "   - Noise reduction → Segmentation → Windowing → Normalization.\n",
    "3. **Feature Extraction:**\n",
    "   - MFCCs + Prosodic features.\n",
    "4. **Feature Selection:**\n",
    "   - PCA or other reduction techniques.\n",
    "5. **Model Training:**\n",
    "   - Train and tune classifiers (SVM).\n",
    "6. **Evaluation:**\n",
    "   - Test with metrics like accuracy and F1-score.\n",
    "7. **Prediction:**\n",
    "   - Deploy for real-time classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and saving the 100 .wav files under their original names, as they appear in the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 00001.wav...\n",
      "Downloading 00001.wav...\n",
      "Downloading 00002.wav...\n",
      "Downloading 00002.wav...\n",
      "Downloading 00003.wav...\n",
      "Downloading 00003.wav...\n",
      "Downloading 00004.wav...\n",
      "Downloading 00004.wav...\n",
      "Downloading 00005.wav...\n",
      "Downloading 00005.wav...\n",
      "Downloading 00006.wav...\n",
      "Downloading 00006.wav...\n",
      "Downloading 00007.wav...\n",
      "Downloading 00007.wav...\n",
      "Downloading 00008.wav...\n",
      "Downloading 00008.wav...\n",
      "Downloading 00009.wav...\n",
      "Downloading 00009.wav...\n",
      "Downloading 00010.wav...\n",
      "Downloading 00010.wav...\n",
      "Downloading 00011.wav...\n",
      "Downloading 00011.wav...\n",
      "Downloading 00012.wav...\n",
      "Downloading 00012.wav...\n",
      "Downloading 00013.wav...\n",
      "Downloading 00013.wav...\n",
      "Downloading 00014.wav...\n",
      "Downloading 00014.wav...\n",
      "Downloading 00015.wav...\n",
      "Downloading 00015.wav...\n",
      "Downloading 00016.wav...\n",
      "Downloading 00016.wav...\n",
      "Downloading 00017.wav...\n",
      "Downloading 00017.wav...\n",
      "Downloading 00018.wav...\n",
      "Downloading 00018.wav...\n",
      "Downloading 00019.wav...\n",
      "Downloading 00019.wav...\n",
      "Downloading 00020.wav...\n",
      "Downloading 00020.wav...\n",
      "Downloading 00021.wav...\n",
      "Downloading 00021.wav...\n",
      "Downloading 00022.wav...\n",
      "Downloading 00022.wav...\n",
      "Downloading 00023.wav...\n",
      "Downloading 00023.wav...\n",
      "Downloading 00024.wav...\n",
      "Downloading 00024.wav...\n",
      "Downloading 00025.wav...\n",
      "Downloading 00025.wav...\n",
      "Downloading 00026.wav...\n",
      "Downloading 00026.wav...\n",
      "Downloading 00027.wav...\n",
      "Downloading 00027.wav...\n",
      "Downloading 00028.wav...\n",
      "Downloading 00028.wav...\n",
      "Downloading 00029.wav...\n",
      "Downloading 00029.wav...\n",
      "Downloading 00030.wav...\n",
      "Downloading 00030.wav...\n",
      "Downloading 00031.wav...\n",
      "Downloading 00031.wav...\n",
      "Downloading 00032.wav...\n",
      "Downloading 00032.wav...\n",
      "Downloading 00033.wav...\n",
      "Downloading 00033.wav...\n",
      "Downloading 00034.wav...\n",
      "Downloading 00034.wav...\n",
      "Downloading 00035.wav...\n",
      "Downloading 00035.wav...\n",
      "Downloading 00036.wav...\n",
      "Downloading 00036.wav...\n",
      "Downloading 00037.wav...\n",
      "Downloading 00037.wav...\n",
      "Downloading 00038.wav...\n",
      "Downloading 00038.wav...\n",
      "Downloading 00039.wav...\n",
      "Downloading 00039.wav...\n",
      "Downloading 00040.wav...\n",
      "Downloading 00040.wav...\n",
      "Downloading 00041.wav...\n",
      "Downloading 00041.wav...\n",
      "Downloading 00042.wav...\n",
      "Downloading 00042.wav...\n",
      "Downloading 00043.wav...\n",
      "Downloading 00043.wav...\n",
      "Downloading 00044.wav...\n",
      "Downloading 00044.wav...\n",
      "Downloading 00045.wav...\n",
      "Downloading 00045.wav...\n",
      "Downloading 00046.wav...\n",
      "Downloading 00046.wav...\n",
      "Downloading 00047.wav...\n",
      "Downloading 00047.wav...\n",
      "Downloading 00048.wav...\n",
      "Downloading 00048.wav...\n",
      "Downloading 00049.wav...\n",
      "Downloading 00049.wav...\n",
      "Downloading 00050.wav...\n",
      "Downloading 00050.wav...\n",
      "Downloading 00051.wav...\n",
      "Downloading 00051.wav...\n",
      "Downloading 00052.wav...\n",
      "Downloading 00052.wav...\n",
      "Downloading 00053.wav...\n",
      "Downloading 00053.wav...\n",
      "Downloading 00054.wav...\n",
      "Downloading 00054.wav...\n",
      "Downloading 00055.wav...\n",
      "Downloading 00055.wav...\n",
      "Downloading 00056.wav...\n",
      "Downloading 00056.wav...\n",
      "Downloading 00057.wav...\n",
      "Downloading 00057.wav...\n",
      "Downloading 00058.wav...\n",
      "Downloading 00058.wav...\n",
      "Downloading 00059.wav...\n",
      "Downloading 00059.wav...\n",
      "Downloading 00060.wav...\n",
      "Downloading 00060.wav...\n",
      "Downloading 00061.wav...\n",
      "Downloading 00061.wav...\n",
      "Downloading 00062.wav...\n",
      "Downloading 00062.wav...\n",
      "Downloading 00063.wav...\n",
      "Downloading 00063.wav...\n",
      "Downloading 00064.wav...\n",
      "Downloading 00064.wav...\n",
      "Downloading 00065.wav...\n",
      "Downloading 00065.wav...\n",
      "Downloading 00066.wav...\n",
      "Downloading 00066.wav...\n",
      "Downloading 00067.wav...\n",
      "Downloading 00067.wav...\n",
      "Downloading 00068.wav...\n",
      "Downloading 00068.wav...\n",
      "Downloading 00069.wav...\n",
      "Downloading 00069.wav...\n",
      "Downloading 00070.wav...\n",
      "Downloading 00070.wav...\n",
      "Downloading 00071.wav...\n",
      "Downloading 00071.wav...\n",
      "Downloading 00072.wav...\n",
      "Downloading 00072.wav...\n",
      "Downloading 00073.wav...\n",
      "Downloading 00073.wav...\n",
      "Downloading 00074.wav...\n",
      "Downloading 00074.wav...\n",
      "Downloading 00075.wav...\n",
      "Downloading 00075.wav...\n",
      "Downloading 00076.wav...\n",
      "Downloading 00076.wav...\n",
      "Downloading 00077.wav...\n",
      "Downloading 00077.wav...\n",
      "Downloading 00078.wav...\n",
      "Downloading 00078.wav...\n",
      "Downloading 00079.wav...\n",
      "Downloading 00079.wav...\n",
      "Downloading 00080.wav...\n",
      "Downloading 00080.wav...\n",
      "Downloading 00081.wav...\n",
      "Downloading 00081.wav...\n",
      "Downloading 00082.wav...\n",
      "Downloading 00082.wav...\n",
      "Downloading 00083.wav...\n",
      "Downloading 00083.wav...\n",
      "Downloading 00084.wav...\n",
      "Downloading 00084.wav...\n",
      "Downloading 00085.wav...\n",
      "Downloading 00085.wav...\n",
      "Downloading 00086.wav...\n",
      "Downloading 00086.wav...\n",
      "Downloading 00087.wav...\n",
      "Downloading 00087.wav...\n",
      "Downloading 00088.wav...\n",
      "Downloading 00088.wav...\n",
      "Downloading 00089.wav...\n",
      "Downloading 00089.wav...\n",
      "Downloading 00090.wav...\n",
      "Downloading 00090.wav...\n",
      "Downloading 00091.wav...\n",
      "Downloading 00091.wav...\n",
      "Downloading 00092.wav...\n",
      "Downloading 00092.wav...\n",
      "Downloading 00093.wav...\n",
      "Downloading 00093.wav...\n",
      "Downloading 00094.wav...\n",
      "Downloading 00094.wav...\n",
      "Downloading 00095.wav...\n",
      "Downloading 00095.wav...\n",
      "Downloading 00096.wav...\n",
      "Downloading 00096.wav...\n",
      "Downloading 00097.wav...\n",
      "Downloading 00097.wav...\n",
      "Downloading 00098.wav...\n",
      "Downloading 00098.wav...\n",
      "Downloading 00099.wav...\n",
      "Downloading 00099.wav...\n",
      "Downloading 00100.wav...\n",
      "Downloading 00100.wav...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# GitHub folder URL\n",
    "url = \"https://github.com/MLEndDatasets/Deception/tree/main/MLEndDD_stories_small\"\n",
    "\n",
    "# Base URL for raw file downloads\n",
    "raw_base = \"https://raw.githubusercontent.com/MLEndDatasets/Deception/main/MLEndDD_stories_small/\"\n",
    "\n",
    "# Get list of .wav files\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "wav_files = [a['href'].split('/')[-1] for a in soup.find_all('a', href=True) if a['href'].endswith('.wav')]\n",
    "\n",
    "# Download each .wav file\n",
    "for file in wav_files:\n",
    "    file_url = raw_base + file\n",
    "    print(f\"Downloading {file}...\")\n",
    "    with open(file, 'wb') as f:\n",
    "        f.write(requests.get(file_url).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the QMUL MLEnd Deception Dataset, and saving it under the variable 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Language</th>\n",
       "      <th>Story_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.wav</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.wav</td>\n",
       "      <td>English</td>\n",
       "      <td>true_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.wav</td>\n",
       "      <td>English</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.wav</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.wav</td>\n",
       "      <td>English</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename Language       Story_type\n",
       "0  00001.wav    Hindi  deceptive_story\n",
       "1  00002.wav  English       true_story\n",
       "2  00003.wav  English  deceptive_story\n",
       "3  00004.wav  Bengali  deceptive_story\n",
       "4  00005.wav  English  deceptive_story"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('MLEndDD_story_attributes_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1nDXnzYLLH6"
   },
   "source": [
    "## 4.1 Transformation stage\n",
    "\n",
    "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F5_kI95LuZ2"
   },
   "source": [
    "## 4.2 Model stage\n",
    "\n",
    "Describe the ML model(s) that you will build. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Ensemble stage\n",
    "\n",
    "Describe any ensemble approach you might have included. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZQPxztuL9AW"
   },
   "source": [
    "# 5 Dataset\n",
    "\n",
    "Describe the datasets that you will create to build and evaluate your models. Your datasets need to be based on our MLEnd Deception Dataset. After describing the datasets, build them here. You can explore and visualise the datasets here as well. \n",
    "\n",
    "If you are building separate training and validatio datasets, do it here. Explain clearly how you are building such datasets, how you are ensuring that they serve their purpose (i.e. they are independent and consist of IID samples) and any limitations you might think of. It is always important to identify any limitations as early as possible. The scope and validity of your conclusions will depend on your ability to understand the limitations of your approach.\n",
    "\n",
    "If you are exploring different datasets, create different subsections for each dataset and give them a name (e.g. 5.1 Dataset A, 5.2 Dataset B, 5.3 Dataset 5.3) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qf7GN1aeXJI"
   },
   "source": [
    "# 6 Experiments and results\n",
    "\n",
    "Carry out your experiments here. Analyse and explain your results. Unexplained results are worthless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSrJCR_cekPO"
   },
   "source": [
    "# 7 Conclusions\n",
    "\n",
    "Your conclusions, suggestions for improvements, etc should go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 References\n",
    "\n",
    "Acknowledge others here (books, papers, repositories, libraries, tools) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
